---
title: "To Preserve Its Surveillance Empire, This Powerful Tech Company Is Deploying a Free Speech Law Meant to Protect Traditional Activists From Bogus Lawsuits"
index: 0
draft: false
contentType: "Op-Ed"
coverImg: "/img/9_ways/home_9_ways.png"
coverImgAlt: "A dithered image of a grid of images selected from a dataset"
preposition: "by"
authors: "Nicola Morrow & Melodi Dincer"
excerpt: "Clearview AI is a lucrative facial recognition company that has spent the past few years in legal hot water. To the company’s chagrin, several European countries have fined Clearview millions for violating their data protections laws by scraping billions of images of peoples’ faces from popular social media websites without their knowledge or consent in order to build its facial recognition app. So far, these moves have failed to stop Clearview from profiting from our data. But as lawsuits against Clearview continue to mount, the company has invoked a dangerous legal argument that, if successful, could provide a playbook for numerous AI companies to evade accountability."
---


[Clearview](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html) AI is a lucrative [facial recognition](https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/) company that has spent the past few years in legal hot water. To the company’s [chagrin](https://www.theguardian.com/technology/2022/may/25/techscape-clearview-ai-facial-recognition-fine), [several](https://techcrunch.com/2023/05/10/clearview-ai-another-cnil-gspr-fine/) [European](https://edpb.europa.eu/news/national-news/2022/facial-recognition-italian-sa-fines-clearview-ai-eur-20-million_en) [countries](https://techcrunch.com/2022/07/13/clearview-greek-ban-order/) have fined Clearview millions for violating their data protections laws by [scraping](https://www.wired.com/story/clearview-ai-scraping-web/) [billions of images](https://www.businessinsider.com/clearview-scraped-30-billion-images-facebook-police-facial-recogntion-database-2023-4) of peoples’ faces from popular social media websites without their knowledge or [consent](https://jolt.law.harvard.edu/digest/clearview-ai-responds-to-cease-and-desist-letters-by-claiming-first-amendment-right-to-publicly-available-data) in order to build its facial recognition app. So far, these moves have failed to stop Clearview from [profiting](https://www.nytimes.com/2021/07/21/technology/clearview-ai-valuation.html) from our data. But as lawsuits against Clearview continue to mount, the company has invoked a dangerous legal argument that, if successful, could provide a playbook for numerous [AI companies](https://news.artnet.com/art-world/class-action-lawsuit-lensa-ai-prisma-labs-biometric-information-2257096) to evade accountability. 

Today, Clearview’s main U.S. customers are law enforcement agencies who use the facial recognition app to identify people from photos and surveillance footage. The police have a [long ]history](https://www.fastcompany.com/90511912/the-long-ugly-history-of-how-police-have-tracked-protesters) of surveilling activists using [powerful new technologies](https://www.eff.org/press/releases/eff-aclu-brief-sfpd-violated-surveillance-law-spying-protests-black-lives), [chilling their basic rights](https://freedomhouse.org/article/how-domestic-spying-tools-undermine-racial-justice-protests) to assemble and protest. In an ongoing lawsuit in California, immigrant rights activists and organizations are [suing Clearview](https://www.justfutureslaw.org/legal-filings/clearview) for misappropriating images of their faces, invading their privacy when it built its app and when it licensed the app to local police departments to use during protests. This allegedly deters protestors from exercising their First Amendment rights out of fear that they will be harmed if police feed images of their faces into Clearview’s AI-run surveillance machine and identify them from Clearview’s scraped sea of faces–a fear grounded in reality, as U.S. police departments in the U.S. consistently respond to lawful protests by [deploying Clearview’s](https://onezero.medium.com/facial-recognition-is-law-enforcements-newest-weapon-against-protestors-c7a9760e46eb) app on protestors.

Clearview, no stranger to [the courtroom](https://www.aclu.org/cases/aclu-v-clearview-ai), has responded to the activists’ lawsuit by trying to get the case tossed out of court early on. The company is testing out a legal strategy to nip the activists’ lawsuit in the bud and avoid having to go through the “discovery” phase of their lawsuit, where it would have to turn over information that could include the development and inner-workings of its app. Once exchanged, this valuable information could help prove Clearview violated the activists’ rights and later, through court filings, become [publicly accessible](https://www.reuters.com/investigates/special-report/usa-courts-secrecy-lobbyist/). This would make Clearview’s technology and business practices more [transparent](https://www.gmfus.org/news/transparency-and-accountability-mechanisms-facial-recognition) to lawmakers, who could then craft [regulations](https://www.congress.gov/bill/117th-congress/senate-bill/2052/text) reigning it in. 

The stakes are high, so Clearview is aggressively pursuing various legal arguments. But at the heart of its legal strategy is a law that should not even apply to Clearview in the first place. 

The strategy involves what’s called an “[anti-SLAPP](https://www.rcfp.org/anti-slapp-legal-guide/#:~:text=Anti%2DSLAPP%20laws%20provide%20defendants,%2C%20petition%2C%20or%20association%20rights.)” law, designed to protect defendants from “Strategic Lawsuits Against Public Participation” (SLAPP). In SLAPP lawsuits, powerful entities sue their opponents in order to intimidate, censor, or silence them from engaging in protests, petitioning the government, or public discourse. The suits are strategic–not substantive–designed to bury innocent defendants in costly litigation until they give up or go bankrupt. [California’s anti-SLAPP law](https://www.sfbar.org/wp-content/uploads/2021/06/anti-slapp.pdf) protects defendants in these cases by allowing them to file [a motion](https://leginfo.legislature.ca.gov/faces/codes_displaySection.xhtml?sectionNum=425.16.&lawCode=CCP) early on in the case, describing how the lawsuit targets their lawful activities. If successful, the burden then shifts to the party suing to prove their lawsuit has merit and is not an attempt to squelch speech. If the judge finds the lawsuit is a SLAPP, they will dismiss the case and can order plaintiffs to pay defendants’ attorneys fees and court costs.

Anti-SLAPP laws are designed to protect free-speech minded Davids from powerful and often secretive Goliaths that exploit our [highly litigious](https://statmodeling.stat.columbia.edu/2015/12/03/why-us-litigious/) society. In California, the prototypical case is when a large land developer sues environmental activists for protesting projects that pollute the local area by picketing construction sites or speaking out at community meetings. Rather than endure these lengthy, expensive, and punishing lawsuits, the activists can file an anti-SLAPP motion and get the case kicked out before it costs them too much. 

In a strategic twist, Clearview filed an [anti-SLAPP motion](https://drive.google.com/drive/recent) against the community activists challenging its facial recognition app in court. Goliath has turned David’s shield into a blunt cudgel, attempting to insulate Clearview’s surveillance empire from legal scrutiny. Cloaking itself in activists’ clothing, Clearview argues that scraping billions of photos from the internet without consent, using them to train its AI systems, and then selling its facial recognition app to police was akin to public participation activity such as petitioning the government, publishing news articles, or organizing public protests. It demands that the suit be dismissed quickly, without allowing the activists any chance to gather evidence, depose witnesses, or have experts issue reports to the court on how Clearview’s technology might violate their rights.

Clearview is wrong, both legally and logically. Legally, Clearview has to show that through building and selling its app, the company is attempting to participate in an important public conversation. To do so, it tries to argue that its business is a central part of the public conversation about crime and the identification of criminals because some of its customers have, at times, used the app during isolated criminal investigations. But even in these scenarios, Clearview is not part of the public conversation – it merely provides the product that some of its users use to match photographs to faces. In those cases, if anyone is part of a “conversation”, it is the user, not Clearview. Once it sells its app, what police do with it is out of Clearview’s control. Moreover, Clearview is a notoriously secret company that repeatedly [attempts](https://www.clearview.ai/principles) to [distance](https://www.nytimes.com/2023/03/31/technology/facial-recognition-false-arrests.html) itself from the downstream effects of its surveillance tool – in essence removing itself from the public conversation as often as it can. Fortunately, the California trial court rejected Clearview’s argument along these lines. The judge found that the activists were not suing to silence some concerned citizen showing a police officer an image she took on her phone at the crime scene; instead, they were challenging a business profiting from illegally appropriating images to sell a product to customers. 

Clearview is now appealing the trial court’s decision, and a lot hangs in the balance. If Clearview succeeds, not only will it thwart the activists’ opportunity to vindicate their rights, but it could also provide a playbook for other [AI companies](https://www.reuters.com/legal/texas-sues-google-allegedly-capturing-biometric-data-millions-without-consent-2022-10-20/) seeking to avoid liability for misusing our data–especially data about our [biological features](https://legal.thomsonreuters.com/en/insights/articles/the-basics-usage-and-privacy-concerns-of-biometric-data)–for their own profit. As over 32 states have anti-SLAPP laws on the books, tech companies could soon use anti-SLAPP motions to undermine our chances of regulating AI products built from the exploitation of our data. Because of its significance, Clearview may fight this battle up to California’s Supreme Court and beyond. But facial recognition systems that promise to identify any person affects each of us individually, and all of us collectively. By rejecting Clearview’s contortion of anti-SLAPP law, courts will ensure tech companies view us as more than mere data points to aggregate and train algorithms on. The law would empower us to control our dataflows and preserve our innate value from the commodifying gaze of the machine.


*Note: The Knowing Machines Research Project filed an [amici curiae brief](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4238870) in support of the Plaintiffs before the trial court in the [lawsuit](https://www.justfutureslaw.org/legal-filings/clearview) discussed in this piece.*
