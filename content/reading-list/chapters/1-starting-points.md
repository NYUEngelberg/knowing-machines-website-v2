This section contains a broad set of introductory texts and locales to ground the study of training data. Resources included in this section cover the politics, possibilities, and pitfalls of ML training data and offer early provocations for thinking about particular aspects of training data, such as privacy or bias.

1.   Barocas, S., & Selbst, A. D. (2016). Big Data’s Disparate Impact. _California Law Review,104_(3), 671–732. [https://www.californialawreview.org/wp-content/uploads/2016/06/2Barocas-Selbst.pdf](https://www.californialawreview.org/wp-content/uploads/2016/06/2Barocas-Selbst.pdf)
2.   Crawford, K. (2021). _Atlas of AI: Power, Politics and the Planetary Costs of Artificial Intelligence,_ see ‘Data’ chapter (pp. 89-122). New Haven, CT: Yale University Press. 
3.   Crawford, K., & Paglen, T. (2019). Excavating AI: The Politics of Images in Machine Learning Training Sets. [https://excavating.ai](https://excavating.ai)
4.   Denton, E., Hanna, A., Amironesei, R., Smart, A., Nicole, H., & Scheuerman, M. K. (2020). Bringing the People Back In: Contesting Benchmark Machine Learning Datasets. 6. _ArXiv_. [https://arxiv.org/abs/2007.07399](https://arxiv.org/abs/2007.07399)
5.   Harvey, A. (2021). _Exposing.ai: Face and Biometric Image Datasets_. [https://exposing.ai/datasets/](https://exposing.ai/datasets/)
6.   MacKenzie, A., & Munster, A. (2019). Platform Seeing: Image Ensembles and Their Invisualities. _Theory, Culture & Society, 36_(5), 3–22. [https://doi.org/10.1177/0263276419847508](https://doi.org/10.1177/0263276419847508)
7.   Miceli, M., Posada, J., & Yang, T. (2022). Studying Up Machine Learning Data: Why Talk About Bias When We Mean Power? _Proceedings of the ACM on Human-Computer Interaction, 6_(GROUP), 1–14. [https://doi.org/10.1145/3492853](https://doi.org/10.1145/3492853)
8.   Paullada, A., Raji, I. D., Bender, E. M., Denton, E., & Hanna, A. (2020). Data and Its (Dis)Contents: A Survey of Dataset Development and Use in Machine Learning Research. _ArXiv_. [https://arxiv.org/abs/2012.05345v1](https://urldefense.com/v3/__https://arxiv.org/abs/2012.05345v1__;!!LIr3w8kk_Xxm!8b-dYz-Rsa7iMiBfoUZfFcOUl8g_my0VNHnOmE-6dmTJHkV49S2av1if6pi7lHgn$)
9.   Roberge, J., & Castelle, M. (Eds.). (2020). _The Cultural Life of Machine Learning: An Incursion into Critical AI Studies_ (1st ed. 2021 edition). Palgrave Macmillan.
10.   Srinivasan, R., & Chander, A. (2021). Biases in AI Systems: A Survey for Practitioners. _Queue, 19_(2), 45-64. [https://doi.org/10.1145/3466132.3466134](https://doi.org/10.1145/3466132.3466134)
11.   Suresh, H., & Guttag, J. V. (2021). A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle. _ArXiv_. [http://arxiv.org/abs/1901.10002](http://arxiv.org/abs/1901.10002)
12.   Thylstrup, N. B. (2022). The Ethics and Politics of Data Sets in the Age of Machine Learning: Deleting Traces and Encountering Remains. _Media, Culture & Society._ [https://doi.org/10.1177/01634437211060226](https://doi.org/10.1177/01634437211060226)