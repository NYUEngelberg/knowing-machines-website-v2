​Training data requires significant human and computational effort to create. It is through this process of production that many of the effects of training data come to be shaped, from the processes of collection to labeling, deployment to deprecation. Texts in this section provide glimpses into the work behind datasets from varying angles, whether examining these production processes from a critical lens or describing the overall workflow of training data production from a technical standpoint.

### **a. Sociotechnical / Critical Approaches to Labor of Training Data** 

These texts draw on approaches and frameworks from science and technology studies, political economy, and labor studies to examine the production of training data from a critical lens, understanding how power relations are at work in this process.

*   Famularo, J., Hensellek, B., & Walsh, P. (2021). Data Stewardship: A Letter to Computer Vision from Cultural Heritage Studies. _CVPR 2021_. [https://www.academia.edu/49423941/Data_Stewardship_A_Letter_to_Computer_Vision_from_Cultural_Heritage_Studies?auto=citations&from=cover_page](https://www.academia.edu/49423941/Data_Stewardship_A_Letter_to_Computer_Vision_from_Cultural_Heritage_Studies?auto=citations&from=cover_page)
*   Gray, M. L., & Suri, S. (2019)._Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass_, see ‘Introduction: Ghosts in the Machine’ (pp. ix-xxxi) and ‘1. Humans in the Loop’ (pp. 1-38). Houghton Mifflin Harcourt.
*   Goetze, T. S., & Abramson, D. (2021). Bigger Isn’t Better: The Ethical and Scientific Vices of Extra-Large Datasets in Language Models. _WebSci_, pp. 69-75. [https://doi.org/10.1145/3462741.3466809](https://doi.org/10.1145/3462741.3466809) 
*   Iliadis, A. (2019). The Tower of Babel problem: Making data make sense with Basic Formal Ontology. _Online Information Review_, 43(6), 1021–1045. [https://doi.org/10.1108/OIR-07-2018-0210](https://doi.org/10.1108/OIR-07-2018-0210)
*   Jones, P. (2021, September 22). Refugees Help Power Machine Learning Advances at Microsoft, Facebook, and Amazon. _Rest of World_. [https://restofworld.org/2021/refugees-machine-learning-big-tech/](https://restofworld.org/2021/refugees-machine-learning-big-tech/)
*   Miceli, M., Schuessler, M., & Yang, T. (2020). Between Subjectivity and Imposition: Power Dynamics in Data Annotation for Computer Vision. _Proceedings of the ACM on Human-Computer Interaction, 4(_CSCW2_)_, 1-25. [https://doi.org/10.1145/3415186](https://doi.org/10.1145/3415186)
*   Newlands, G. (2021). Lifting the Curtain: Strategic Visibility of Human Labour in AI-as-a-Service. _Big Data & Society_, _8_(1), 1-14. [https://doi.org/10.1177/20539517211016026](https://urldefense.com/v3/__https://doi.org/10.1177/20539517211016026__;!!LIr3w8kk_Xxm!8b-dYz-Rsa7iMiBfoUZfFcOUl8g_my0VNHnOmE-6dmTJHkV49S2av1if6vAHzT2B$)
*   Sachs, S. E. (2020). The Algorithm At Work? Explanation and Repair in the Enactment of Similarity in Art Data. _Information, Communication & Society, 23_(11), 1689–1705. [https://doi.org/10.1080/1369118X.2019.1612933](https://doi.org/10.1080/1369118X.2019.1612933)
*   Sambasivan, N. (2021). Seeing Like a Dataset from the Global South. _Interactions, 28_(4), 76–78. [https://doi.org/10.1145/3466160](https://doi.org/10.1145/3466160)
*   Sap, M., Card, D., Gabriel, S., Choi, Y., & Smith, N. A. (2019). The Risk of Racial Bias in Hate Speech Detection. _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, 1668–1678. [https://doi.org/10.18653/v1/P19-1163](https://doi.org/10.18653/v1/P19-1163)

### **b. Organizational Workflows in Dataset Production** 

Texts included here look to training data production from a practitioner-oriented lens. They survey either the entire workflow of training data production or specific stages within this process to identify challenges and suggest best practices.

*   Amershi, S., Begel, A., Bird, C., DeLine, R., Gall, H., Kamar, E., Nagappan, N., Nushi, B., & Zimmermann, T. (2019). Software Engineering for Machine Learning: A Case Study. _2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)_, 291–300. [https://doi.org/10.1109/ICSE-SEIP.2019.00042](https://doi.org/10.1109/ICSE-SEIP.2019.00042)
*   Ashmore, R., Calinescu, R., & Paterson, C. (2019). Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges. _ArXiv_. [http://arxiv.org/abs/1905.04223](http://arxiv.org/abs/1905.04223)
*   Barclay, I., Taylor, H., Preece, A., Taylor, I., Verma, D., & de Mel, G. (2020). A Framework for Fostering Transparency in Shared Artificial Intelligence Models by Increasing Visibility of Contributions. _Concurrency and Computation: Practice and Experience, 33_(19), e6129. [https://doi.org/10.1002/cpe.6129](https://doi.org/10.1002/cpe.6129)
*   Bhardwaj, A., Bhattacherjee, S., Chavan, A., Deshpande, A., Elmore, A. J., Madden, S., & Parameswaran, A. G. (2014). DataHub: Collaborative Data Science & Dataset Version Management at Scale. _ArXiv_. [http://arxiv.org/abs/1409.0798](http://arxiv.org/abs/1409.0798)
*   Chandrabose, A., & Chakravarthi, B. R. (2021). An Overview of Fairness in Data – Illuminating the Bias in Data Pipeline. _LTEDI_. [https://aclanthology.org/2021.ltedi-1.5](https://aclanthology.org/2021.ltedi-1.5)
*   Dong, W., & Fu, W.-T. (2010). Cultural Difference in Image Tagging. _Proceedings of the SIGCHI Conference on Human Factors in Computing Systems_, 981–984. [https://doi.org/10.1145/1753326.1753472](https://doi.org/10.1145/1753326.1753472)
*   Hanley, M., Khandelwal, A., Averbuch-Elor, H., Snavely, N., & Nissenbaum, H. (2020). An Ethical Highlighter for People-Centric Dataset Creation. _ArXiv_. [http://arxiv.org/abs/2011.13583](http://arxiv.org/abs/2011.13583)
*   Hutchinson, B., Smart, A., Hanna, A., Denton, E., Greer, C., Kjartansson, O., Barnes, P., & Mitchell, M. (2021). Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure. _ArXiv_. [http://arxiv.org/abs/2010.13561](http://arxiv.org/abs/2010.13561)
*   Geiger, R., Cope, D., Ip, J., Lotosh, M., Shah, A., Weng, J., & Tang, R. (2021). “Garbage In, Garbage Out” Revisited: What Do Machine Learning Application Papers Report About Human-Labeled Training Data? _ArXiv_. [https://doi.org/10.1162/qss_a_00144](https://doi.org/10.1162/qss_a_00144)
*   Holstein, K., Vaughan, J. W., Daumé III, H., Dudík, M., & Wallach, H. (2019). Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need? _Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems_, 1–16. [https://doi.org/10.1145/3290605.3300830](https://doi.org/10.1145/3290605.3300830)
*   Muller, M. J., Wolf, C. T., Andres, J., Desmond, M., Joshi, N. N., Ashktorab, Z., Sharma, A., Brimijoin, K., Pan, Q., Duesterwald, E., & Dugan, C. (2021). Designing Ground Truth and the Social Life of Labels. _Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems_, 1-16. [https://doi.org/10.1145/3411764.3445402](https://doi.org/10.1145/3411764.3445402)
*   Polyzotis, N., Roy, S., Whang, S. E., & Zinkevich, M. (2018). Data Lifecycle Challenges in Production Machine Learning: A Survey. _ACM SIGMOD Record_, _47_(2), 17–28. [https://doi.org/10.1145/3299887.3299891](https://doi.org/10.1145/3299887.3299891)
*   Roh, Y., Heo, G., & Whang, S. E. (2021). A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective. _IEEE Transactions on Knowledge and Data Engineering, 33_(4), 1328–1347. [https://doi.org/10.1109/TKDE.2019.2946162](https://doi.org/10.1109/TKDE.2019.2946162)
*   Tatman, R. (2018). Setting Up Your Public Data for Success. _2018 IEEE International Conference on Big Data (Big Data)_, 3261–3262. [https://doi.org/10.1109/BigData.2018.8622190](https://doi.org/10.1109/BigData.2018.8622190)
*   Sachdeva, P. S., Barreto, R., von Vacano, C., & Kennedy, C. J. (2022). Assessing Annotator Identity Sensitivity via Item Response Theory: A Case Study in a Hate Speech Corpus. _2022 ACM Conference on Fairness, Accountability, and Transparency_, 1585–1603. [https://doi.org/10.1145/3531146.3533216](https://doi.org/10.1145/3531146.3533216)
*   Sambasivan, N., & Veeraraghavan, R. (2022). The Deskilling of Domain Expertise in AI Development. _Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems_, 1-14. [https://doi.org/10.1145/3491102.3517578](https://doi.org/10.1145/3491102.3517578)
*   Shanmugam, D., Diaz, F., Shabanian, S., Funck, M., & Biega, A. (2022). Learning to Limit Data Collection via Scaling Laws: A Computational Interpretation for the Legal Principle of Data Minimization. _2022 ACM Conference on Fairness, Accountability, and Transparency_, 839-849. [https://doi.org/10.1145/3531146.3533148](https://doi.org/10.1145/3531146.3533148)
*   Vaughan, J. W. (2018). Making Better Use of the Crowd: How Crowdsourcing Can Advance Machine Learning Research. _Journal of Machine Learning Research, 18_(193), 1–46. [https://dl.acm.org/doi/10.5555/3122009.3242050](https://dl.acm.org/doi/10.5555/3122009.3242050)
*   Wang, D., Prabhat, S., & Sambasivan, N. (2022). Whose AI Dream? In search of the aspiration in data annotation. _Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems_, 1-16. [https://doi.org/10.1145/3491102.3502121](https://doi.org/10.1145/3491102.3502121)