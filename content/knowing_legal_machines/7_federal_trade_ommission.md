---
title: "Comments of the Knowing Machines Research Project to the Federal Trade Commission"
index: 7
draft: false
contentType: "Comment"
coverImg: "/img/legal/7.png"
coverImgAlt: "A dithered abstract image of a mesh."
preposition: "by"
authors: "Melodi Dincer & Kate Crawford"
excerpt: "With this Comment, the Knowing Machines Project asks the Commission to investigate and, where appropriate, prohibit the deceptive and unfair practices that emotion recognition companies conduct."
---
[Download ↓](public/docs/legal_knowing_machines/FTC-2022-0053-1142_attachment.pdf) 


On August 22, 2022, the Federal Trade Commission published an advance notice of proposed rulemaking (ANPR) requesting public comment on an intended Trade Regulation Rule on Commercial Surveillance and Data Security.

The Knowing Machines Research Project (“Knowing Machines”) appreciates the opportunity to comment.  In response to ANPR Questions 37., 38., 55.,60., and 76., we urge the Commission to consider new rules that forbid or limit the development, design, and use of a biometric commercial surveillance practice known as “emotion recognition.”Emotion recognition technologies claim to be able to detect a person’s internal emotional state based on algorithmic systems trained to analyze facial expressions that appear in photo or video content. These systems are based on the dual premises that (1) facial expressions map onto a limited, universal set of emotions, and (2) algorithmic systems, including machine-learning (ML) tools, can accurately gauge consumers’ feelings to serve commercial ends.
					
While both these premises lack scientific support, the harms these systems pose to consumers are real. Emotion recognition companies deceive consumers with misleading and unsubstantiated claims about what their tools can do, a prototypical “faulty conclusion” flaw fueled by failures in experimental theory, methodology, and design. These tools are unfair to consumers, especially people of color and people with disabilities (PWD) who are likely to bear substantial, unavoidable injury without any countervailing benefits to consumers or competition. These tools also threaten consumer privacy by encouraging the surveillance and assessment of our intimate, private emotions.
With this Comment, the Knowing Machines Project asks the Commission to investigate and, where appropriate, prohibit the deceptive and unfair practices that emotion recognition companies conduct. To aid the Commission’s consideration, we have collected several marketing claims and captured images from promotional materials depicting emotion recognition tools, some of which are described in Section II.B. This is not a comprehensive survey and is offered merely to demonstrate claims made by companies selling these tools. It can be found at the end of this submission in “Appendix: Companies’ Marketing Claims and Depictions of Emotion Recognition Tools.” 

