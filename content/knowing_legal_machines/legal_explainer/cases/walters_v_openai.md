---
index: 10
title: "Walters v. OpenAI"
slug: "walters-v-openai"
coverImg: "/img/legal/explainer/cases/10.png"
coverImgAlt: "A dithered abstract image with lines."
citations: ["Walters v. OpenAI, No. 23-cv-03122 (Ga. Super. Ct.)","Walters v. OpenAI, No. 23-A-04860-2 (Ga. Super. Ct., Gwinnett Cnty.)"]
caseDates: ["7/14/2023","6/5/2023"]
draft: false 
contentType: "legalCase"
relatedQuestions: ["can-i-sue-a-genai-company-for-defamation-if-its-tool-generates-false-information-about-me"]
---
In *Walters v. OpenAI*, the radio talk show host Mark Walters sued OpenAI for defamation after he found out that when a journalist prompted ChatGPT for information about an unrelated lawsuit, the tool falsely described Walters as a defendant in the case who had been accused of fraud.  Walters is seeking monetary compensation from the companies for the alleged reputational damage that their tools caused.

In its initial motion to dismiss, filed on July 21, 2023, OpenAI went out of its way to avoid the conclusion that its outputs should be considered statements of “fact,” [pointing to](https://storage.courtlistener.com/recap/gov.uscourts.gand.318259/gov.uscourts.gand.318259.12.1.pdf) its disclaimers about ChatGPT’s lack of reliability and suggesting that since its outputs are “probabilistic,” they can never really be considered factual statements. Among other things, OpenAI also argued that it fails to meet defamation’s publication requirement. The company refers to its [Terms of Use](https://openai.com/policies/terms-of-use)—which assign users rights to their ChatGPT outputs and states that users are “responsible” for them—to describe ChatGPT as nothing more than “a private drafting tool” that “helps [a user] write or create content owned by the user.” Walters filed an amended complaint on September 8, 2023.


